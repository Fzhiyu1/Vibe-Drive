# 探索文档：主智能体响应优化

## 背景

当前主智能体（Master Agent）实现存在响应延迟问题：
- AI 既要聊天又要控制设备
- ReAct 模式下多次工具调用导致等待时间长
- 用户体验：长时间无反馈

## 问题分析

### 当前架构

```
用户输入 → 主智能体 → [say + 多个控制工具] → 响应
                         ↑
                    串行执行，等待每个工具完成
```

### 延迟来源

1. **LLM 推理时间**：每次工具调用后需要重新推理
2. **工具执行时间**：音乐搜索、API 调用等
3. **多轮循环**：ReAct 模式可能多次循环
4. **say 工具调用过多**：AI 倾向于多次调用 say

---

## 优化方案

### 方案 1：非 ReAct 模式（一次性控制）

**思路**：不使用工具循环，一次性生成所有操作指令

```
用户输入 → LLM 一次性输出 JSON → 解析执行
```

**优点**：
- 响应速度最快（1 次 LLM 调用）
- 实现简单

**缺点**：
- 无法处理复杂多步骤任务
- 无法根据工具结果调整后续操作
- 需要自定义输出解析

**适用场景**：简单指令（"播放音乐"、"开灯"）

---

### 方案 2：先对话再操作

**思路**：通过 Prompt 约束，让 AI 先回复用户，再执行操作

```
用户输入 → 主智能体 → 1. say("好的") → 2. 执行操作
                              ↑
                         用户立即听到回复
```

**优点**：
- 用户体验好，立即得到反馈
- 保持 ReAct 灵活性
- 实现改动小（只改 Prompt）

**缺点**：
- 依赖 Prompt 约束，AI 可能不遵守
- 操作失败时用户已收到"成功"回复

**实现方式**：
```
## 重要规则
1. 收到用户请求后，必须先调用 say 工具回复用户
2. 回复后再执行具体操作
3. 操作完成后不需要再次回复
```

---

### 方案 3：委派式智能体

**思路**：主智能体只负责对话，将操作委派给氛围智能体

```
用户输入 → 主智能体 → say("好的，正在为您编排")
                   ↓
              callVibeAgent(异步) → 氛围智能体执行
```

**优点**：
- 职责分离清晰
- 主智能体响应快
- 氛围智能体专注复杂编排

**缺点**：
- 架构更复杂
- 需要协调两个智能体
- 简单操作也要经过委派

**变体**：主智能体保留简单操作能力
- 简单指令（设置灯光）：直接执行
- 复杂编排（营造氛围）：委派给氛围智能体

---

### 方案 4：混合模式（推荐） ✅ 已选定

**思路**：结合方案 2 和方案 3

```
用户: "帮我放松一下"
    ↓
主智能体:
  1. say("好的，我来为您营造放松氛围")  ← 立即回复
  2. callVibeAgent("放松氛围", async=true) ← 异步委派
    ↓
用户立即听到回复
氛围在后台编排，完成后通知主智能体
```

**核心改动**：
1. Prompt 强调"先说后做"
2. `callVibeAgent` 改为异步执行
3. 主智能体只保留 `say` + `callVibeAgent` + 简单查询工具

---

## 方案 4 详细设计

### 整体架构

```
┌─────────────────────────────────────────────────────────┐
│                    主智能体                              │
│                                                         │
│  工具：                                                  │
│  - say()           对用户说话                            │
│  - callVibeAgent() 异步启动氛围智能体                    │
│  - resetVibe()     终止当前氛围任务                      │
│  - getEnvironment()                                     │
│  - ...                                                  │
└─────────────────────────────────────────────────────────┘
         │                              ↑
         │ 异步启动                     │ 完成/失败消息
         ↓                              │
┌─────────────────────────────────────────────────────────┐
│                 氛围任务管理器                            │
│                                                         │
│  - currentTask: 当前运行的氛围任务（只能有一个）          │
│  - messageQueue: 完成/失败消息队列                       │
│                                                         │
│  方法：                                                  │
│  - startTask()  启动新任务（自动终止旧任务）              │
│  - cancelTask() 终止当前任务                             │
│  - pollMessages() 获取队列中的消息                       │
└─────────────────────────────────────────────────────────┘
         │
         │ 执行
         ↓
┌─────────────────────────────────────────────────────────┐
│                   氛围智能体                             │
└─────────────────────────────────────────────────────────┘
```

### 消息队列机制

氛围智能体完成后，结果进入消息队列，等待主智能体处理。

```
主智能体处理流程：
────────────────
1. 收到用户消息
2. 检查消息队列（氛围完成/失败消息）
3. 将队列消息 + 用户消息一起给 LLM 处理
4. LLM 生成回复，可能调用工具
5. 返回结果
```

**消息类型**：
- `VIBE_SUCCESS`: 氛围编排成功，包含 AmbiencePlan
- `VIBE_FAILED`: 氛围编排失败，包含错误信息

### 并发场景处理

**场景 1：用户没有新对话**
```
主智能体: say("正在编排") → 静默
                              ↓
                        氛围智能体完成，消息入队
                              ↓
                        （等待用户下次对话时处理）
```

**场景 2：用户发起新对话**
```
主智能体: say("正在编排") → 静默
                              ↓
用户: "现在什么天气？"
                              ↓
主智能体: 检查队列 + 处理用户问题
         "今天晴天，对了氛围编排好了"
```

**场景 3：用户换风格（只能有一个氛围运行）**
```
用户: "帮我放松" → 启动氛围 A
用户: "换个风格" → 终止 A，启动氛围 B
```

**场景 4：用户取消**
```
用户: "帮我放松" → 启动氛围
用户: "算了不要了"
         ↓
主智能体: resetVibe() → 终止当前氛围任务
```

### 实时推送机制

氛围智能体执行过程中，工具调用**实时推送**给前端，而不是等完成后再推送。

```
氛围智能体执行流程：
────────────────────
1. setLight() → 实时推送 tool_start/tool_end → 前端立即应用灯光
2. setScent() → 实时推送 tool_start/tool_end → 前端立即应用香氛
3. batchPlayMusic() → 实时推送 → 前端立即播放音乐
4. generateNarrative() → 实时推送 → 前端立即播报 TTS
5. 全部完成 → 完成消息入队 → 等待主智能体处理
```

**推送通道**：通过 SseEventPublisher 按 sessionId 推送

```
┌─────────────────┐
│   氛围智能体     │
│                 │
│  工具执行 ──────────→ SseEventPublisher.publish(sessionId, event)
│                 │                    │
└─────────────────┘                    ↓
                              ┌─────────────────┐
                              │     前端        │
                              │                 │
                              │  实时接收并应用  │
                              └─────────────────┘
```

**事件类型**：
- `vibe_tool_start`: 氛围工具开始执行
- `vibe_tool_end`: 氛围工具执行完成（包含结果）
- `vibe_complete`: 氛围编排全部完成
- `vibe_error`: 氛围编排失败

---

## 实验计划

### 实验 1：Prompt 优化（方案 2）

**目标**：通过 Prompt 约束实现"先说后做"

**改动**：
- 修改 `master-system.txt`
- 强调 say 工具优先级

**验证**：
- [ ] AI 是否先调用 say
- [ ] 响应延迟是否改善

### 实验 2：异步委派（方案 3/4）

**目标**：callVibeAgent 异步执行

**改动**：
- CallVibeAgentTool 改为异步
- 添加完成通知机制

**验证**：
- [ ] 主智能体响应时间
- [ ] 氛围编排是否正常完成

### 实验 3：工具精简

**目标**：减少主智能体的工具数量

**改动**：
- 移除直接控制工具（setLight、setScent 等）
- 只保留：say、callVibeAgent、getEnvironment、getProjectIntro

**验证**：
- [ ] 是否影响简单指令处理
- [ ] 响应速度是否提升

---

## 决策记录

| 日期 | 决策 | 原因 |
|------|------|------|
| 2024-12-27 | 选定方案 4（混合模式） | 兼顾响应速度和灵活性 |
| 2024-12-27 | 异步 callVibeAgent + 消息队列 | 主智能体立即响应，氛围后台执行 |
| 2024-12-27 | 只允许一个氛围任务运行 | 避免冲突，新任务自动终止旧任务 |
| 2024-12-27 | 新增 resetVibe 工具 | 支持用户取消氛围任务 |

---

## TTS 延迟优化探索（2024-12-27）

### 问题背景

用户发出指令后，到听到 AI 回复之间延迟较大。

**延迟来源分析**：
1. LLM 推理时间（TTFT）- 无法优化
2. LLM 生成 say 工具参数 - 需要完整生成后才触发
3. TTS 生成音频 - 可以流式优化
4. 音频播放 - 可以流式优化

### 已实现的优化

#### 优化 1：tool_start 触发 TTS

**改动**：say 工具开始时（tool_start）就触发 TTS，不等 tool_end

**效果**：减少约 500ms 延迟

#### 优化 2：流式 TTS 播放

**改动**：使用 MediaSource API 实现边收边播

**效果**：首字延迟从 1.5-3s 降至 100-300ms

### 进一步优化探索：流式 say 工具

**目标**：LLM 边生成 say 参数，边发送给 TTS 播放

**调研结果**（LangChain4j）：

| 需求 | 是否支持 | 说明 |
|------|----------|------|
| TokenStream 流式工具参数 | ❌ | beforeToolExecution 在参数完整后才触发 |
| 流式工具参数回调 | ❌ | TokenStream 无此回调，需用底层 API |
| 底层 StreamingChatModel | ✅ | 可访问原始流，但需绕过 AiServices |

**底层 API 支持**：OpenAI/DeepSeek API 原生支持流式返回工具参数

```json
{"function_call": {"name": "say", "arguments": "{\"text\": \"你"}}
{"function_call": {"name": "say", "arguments": "好"}}
...
```

**实现方案**：
1. 跳过 AiServices，直接使用 StreamingChatModel
2. 自定义 StreamingChatResponseHandler 解析原始流
3. 检测 say 工具参数 delta，流式推送给前端

**权衡**：
- 改动成本高（需重写对话逻辑，失去 AiServices 便利）
- 收益有限（~300ms 进一步优化）

### 替代方案评估

| 方案 | 可行性 | 风险 |
|------|--------|------|
| `<say>...</say>` 标签 | 中 | LLM 可能不遵循（~85-90%） |
| 所有输出都播放 | 高 | 会播放"思考内容" |
| 第一句话播放 | 高 | 假设第一句是回复 |
| 保持 say 工具 | 高 | 延迟已优化，可接受 |

### 决策

**选择**：保持 say 工具，接受当前延迟

**原因**：
1. 当前优化后延迟已可接受（~300ms 首字）
2. 流式 say 改动成本高，收益有限
3. `<say>` 标签方案可靠性不足

---

## 决策记录

| 日期 | 决策 | 原因 |
|------|------|------|
| 2024-12-27 | 选定方案 4（混合模式） | 兼顾响应速度和灵活性 |
| 2024-12-27 | 异步 callVibeAgent + 消息队列 | 主智能体立即响应，氛围后台执行 |
| 2024-12-27 | 只允许一个氛围任务运行 | 避免冲突，新任务自动终止旧任务 |
| 2024-12-27 | 新增 resetVibe 工具 | 支持用户取消氛围任务 |
| 2024-12-27 | TTS tool_start 触发 + 流式播放 | 降低首字延迟 |
| 2024-12-27 | 保持 say 工具，不做流式参数 | 改动成本高，收益有限 |

---

## 参考

- [探索文档-主智能体设计.md](./探索文档-主智能体设计.md)
- [探索文档-Agent优化.md](./探索文档-Agent优化.md)

### LangChain4j API 说明

- **TokenStream**（高级 API）：`beforeToolExecution` / `onToolExecuted` - 工具执行前后回调
- **StreamingChatResponseHandler**（低级 API）：可访问原始流，需自行解析工具参数 delta
